{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbbzQxuZ4OF2KpTp2sG/2Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fourmodern/toc_tutorial_colab/blob/main/teachopencadd/t043_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keCTRHqP9YtR",
        "outputId": "063cc2e1-b451-4400-97bf-013f43e8ec36"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.3.6-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (11.0.0)\n",
            "Downloading rdkit-2024.3.6-cp310-cp310-manylinux_2_28_x86_64.whl (32.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJFqKC3n887_",
        "outputId": "dbbd3fa3-75c1-4ada-961d-b770e6553a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 다운로드 중...\n",
            "데이터가 성공적으로 다운로드되었습니다: data/250k_rndm_zinc_drugs_clean_3.csv\n",
            "\n",
            "데이터 샘플:\n",
            "                                              smiles     logP       qed  \\\n",
            "0            CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1  5.05060  0.702012   \n",
            "1       C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1  3.11370  0.928975   \n",
            "2  N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...  4.96778  0.599682   \n",
            "3  CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...  4.00022  0.690944   \n",
            "4  N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...  3.60956  0.789027   \n",
            "\n",
            "        SAS  \n",
            "0  2.084095  \n",
            "1  3.432004  \n",
            "2  2.470633  \n",
            "3  2.822753  \n",
            "4  4.035182  \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem import BondType\n",
        "import ast\n",
        "import requests\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "RDLogger.DisableLog(\"rdApp.*\")\n",
        "\n",
        "# 상수 정의\n",
        "SMILE_CHARSET = '[\"C\", \"B\", \"F\", \"I\", \"H\", \"O\", \"N\", \"S\", \"P\", \"Cl\", \"Br\"]'\n",
        "SMILE_CHARSET = ast.literal_eval(SMILE_CHARSET)\n",
        "\n",
        "bond_mapping = {\"SINGLE\": 0, \"DOUBLE\": 1, \"TRIPLE\": 2, \"AROMATIC\": 3}\n",
        "bond_mapping.update(\n",
        "    {0: BondType.SINGLE, 1: BondType.DOUBLE, 2: BondType.TRIPLE, 3: BondType.AROMATIC}\n",
        ")\n",
        "\n",
        "SMILE_to_index = dict((c, i) for i, c in enumerate(SMILE_CHARSET))\n",
        "index_to_SMILE = dict((i, c) for i, c in enumerate(SMILE_CHARSET))\n",
        "atom_mapping = dict(SMILE_to_index)\n",
        "atom_mapping.update(index_to_SMILE)\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "EPOCHS = 10\n",
        "NUM_ATOMS = 120\n",
        "ATOM_DIM = len(SMILE_CHARSET)\n",
        "BOND_DIM = 4 + 1\n",
        "LATENT_DIM = 435\n",
        "\n",
        "def download_file(url, filename):\n",
        "    \"\"\"파일 다운로드 함수\"\"\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# 데이터 파일 경로 설정\n",
        "data_dir = Path('data')\n",
        "data_dir.mkdir(exist_ok=True)\n",
        "csv_path = data_dir / '250k_rndm_zinc_drugs_clean_3.csv'\n",
        "\n",
        "# 데이터 다운로드 (파일이 없는 경우에만)\n",
        "if not csv_path.exists():\n",
        "    url = \"https://raw.githubusercontent.com/aspuru-guzik-group/chemical_vae/master/models/zinc_properties/250k_rndm_zinc_drugs_clean_3.csv\"\n",
        "    print(\"데이터 다운로드 중...\")\n",
        "    success = download_file(url, csv_path)\n",
        "    if success:\n",
        "        print(f\"데이터가 성공적으로 다운로드되었습니다: {csv_path}\")\n",
        "    else:\n",
        "        raise Exception(\"데이터 다운로드 실패\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smiles_to_graph(smiles):\n",
        "    # Converts SMILES to molecule object\n",
        "    molecule = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    # Initialize adjacency and feature tensor\n",
        "    adjacency = np.zeros((BOND_DIM, NUM_ATOMS, NUM_ATOMS), \"float32\")\n",
        "    features = np.zeros((NUM_ATOMS, ATOM_DIM), \"float32\")\n",
        "\n",
        "    # loop over each atom in molecule\n",
        "    for atom in molecule.GetAtoms():\n",
        "        i = atom.GetIdx()\n",
        "        atom_type = atom_mapping[atom.GetSymbol()]\n",
        "        features[i] = np.eye(ATOM_DIM)[atom_type]\n",
        "        # loop over one-hop neighbors\n",
        "        for neighbor in atom.GetNeighbors():\n",
        "            j = neighbor.GetIdx()\n",
        "            bond = molecule.GetBondBetweenAtoms(i, j)\n",
        "            bond_type_idx = bond_mapping[bond.GetBondType().name]\n",
        "            adjacency[bond_type_idx, [i, j], [j, i]] = 1\n",
        "\n",
        "    # Where no bond, add 1 to last channel (indicating \"non-bond\")\n",
        "    # Notice: channels-first\n",
        "    adjacency[-1, np.sum(adjacency, axis=0) == 0] = 1\n",
        "\n",
        "    # Where no atom, add 1 to last column (indicating \"non-atom\")\n",
        "    features[np.where(np.sum(features, axis=1) == 0)[0], -1] = 1\n",
        "\n",
        "    return adjacency, features\n",
        "\n",
        "\n",
        "def graph_to_molecule(graph):\n",
        "    # Unpack graph\n",
        "    adjacency, features = graph\n",
        "\n",
        "    # RWMol is a molecule object intended to be edited\n",
        "    molecule = Chem.RWMol()\n",
        "\n",
        "    # Remove \"no atoms\" & atoms with no bonds\n",
        "    keep_idx = np.where(\n",
        "        (np.argmax(features, axis=1) != ATOM_DIM - 1)\n",
        "        & (np.sum(adjacency[:-1], axis=(0, 1)) != 0)\n",
        "    )[0]\n",
        "    features = features[keep_idx]\n",
        "    adjacency = adjacency[:, keep_idx, :][:, :, keep_idx]\n",
        "\n",
        "    # Add atoms to molecule\n",
        "    for atom_type_idx in np.argmax(features, axis=1):\n",
        "        atom = Chem.Atom(atom_mapping[atom_type_idx])\n",
        "        _ = molecule.AddAtom(atom)\n",
        "\n",
        "    # Add bonds between atoms in molecule; based on the upper triangles\n",
        "    # of the [symmetric] adjacency tensor\n",
        "    (bonds_ij, atoms_i, atoms_j) = np.where(np.triu(adjacency) == 1)\n",
        "    for (bond_ij, atom_i, atom_j) in zip(bonds_ij, atoms_i, atoms_j):\n",
        "        if atom_i == atom_j or bond_ij == BOND_DIM - 1:\n",
        "            continue\n",
        "        bond_type = bond_mapping[bond_ij]\n",
        "        molecule.AddBond(int(atom_i), int(atom_j), bond_type)\n",
        "\n",
        "    # Sanitize the molecule; for more information on sanitization, see\n",
        "    # https://www.rdkit.org/docs/RDKit_Book.html#molecular-sanitization\n",
        "    flag = Chem.SanitizeMol(molecule, catchErrors=True)\n",
        "    # Let's be strict. If sanitization fails, return None\n",
        "    if flag != Chem.SanitizeFlags.SANITIZE_NONE:\n",
        "        return None\n",
        "\n",
        "    return molecule\n",
        "\n",
        "class MoleculeDataset(Dataset):\n",
        "    def __init__(self, df, num_samples=8000):\n",
        "        self.adjacency_tensor = []\n",
        "        self.feature_tensor = []\n",
        "        self.qed_tensor = []\n",
        "\n",
        "        # 데이터 수집\n",
        "        for idx in range(min(num_samples, len(df))):\n",
        "            adjacency, features = smiles_to_graph(df.loc[idx][\"smiles\"])\n",
        "            qed = df.loc[idx][\"qed\"]\n",
        "            self.adjacency_tensor.append(adjacency)\n",
        "            self.feature_tensor.append(features)\n",
        "            self.qed_tensor.append(qed)\n",
        "\n",
        "        # numpy 배열로 먼저 변환\n",
        "        self.adjacency_tensor = np.array(self.adjacency_tensor, dtype=np.float32)\n",
        "        self.feature_tensor = np.array(self.feature_tensor, dtype=np.float32)\n",
        "        self.qed_tensor = np.array(self.qed_tensor, dtype=np.float32)\n",
        "\n",
        "        # numpy 배열을 torch 텐서로 변환\n",
        "        self.adjacency_tensor = torch.from_numpy(self.adjacency_tensor)\n",
        "        self.feature_tensor = torch.from_numpy(self.feature_tensor)\n",
        "        self.qed_tensor = torch.from_numpy(self.qed_tensor)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.qed_tensor)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.adjacency_tensor[idx],\n",
        "                self.feature_tensor[idx],\n",
        "                self.qed_tensor[idx])"
      ],
      "metadata": {
        "id": "09bAUhey9CpY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RelationalGraphConvLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, activation=F.relu, use_bias=False):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.activation = activation\n",
        "        self.use_bias = use_bias\n",
        "\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(BOND_DIM, in_features, out_features))\n",
        "        if use_bias:\n",
        "            self.bias = nn.Parameter(torch.FloatTensor(BOND_DIM, 1, out_features))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        if self.use_bias:\n",
        "            nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, adjacency, features):\n",
        "        # [batch, bond_dim, num_atoms, num_atoms] x [batch, num_atoms, in_features]\n",
        "        support = torch.matmul(adjacency, features.unsqueeze(1))\n",
        "        # Apply weights\n",
        "        output = torch.matmul(support, self.weight)\n",
        "        if self.use_bias:\n",
        "            output = output + self.bias\n",
        "        # Sum over bond types\n",
        "        output = torch.sum(output, dim=1)\n",
        "        return self.activation(output)\n",
        "\n",
        "class Sampling(nn.Module):\n",
        "    def forward(self, z_mean, z_log_var):\n",
        "        batch_size = z_mean.size(0)\n",
        "        latent_dim = z_mean.size(1)\n",
        "        epsilon = torch.randn(batch_size, latent_dim).to(z_mean.device)\n",
        "        return z_mean + torch.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "n27A9q5h9fzy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, gconv_units, dense_units, dropout_rate=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        # Graph Convolution Layers\n",
        "        self.gconv_layers = nn.ModuleList()\n",
        "        in_features = ATOM_DIM\n",
        "        for units in gconv_units:\n",
        "            self.gconv_layers.append(\n",
        "                RelationalGraphConvLayer(in_features, units)\n",
        "            )\n",
        "            in_features = units\n",
        "\n",
        "        # Dense Layers\n",
        "        self.dense_layers = nn.ModuleList()\n",
        "        in_features = gconv_units[-1]\n",
        "        for units in dense_units:\n",
        "            self.dense_layers.append(nn.Sequential(\n",
        "                nn.Linear(in_features, units),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            ))\n",
        "            in_features = units\n",
        "\n",
        "        self.z_mean = nn.Linear(dense_units[-1], LATENT_DIM)\n",
        "        self.z_log_var = nn.Linear(dense_units[-1], LATENT_DIM)\n",
        "\n",
        "    def forward(self, adjacency, features):\n",
        "        x = features\n",
        "        for gconv in self.gconv_layers:\n",
        "            x = gconv(adjacency, x)\n",
        "\n",
        "        # Global pooling\n",
        "        x = torch.mean(x, dim=1)\n",
        "\n",
        "        for dense in self.dense_layers:\n",
        "            x = dense(x)\n",
        "\n",
        "        return self.z_mean(x), self.z_log_var(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, dense_units, dropout_rate=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        # Dense layers\n",
        "        self.dense_layers = nn.ModuleList()\n",
        "        in_features = LATENT_DIM\n",
        "        for units in dense_units:\n",
        "            self.dense_layers.append(nn.Sequential(\n",
        "                nn.Linear(in_features, units),\n",
        "                nn.Tanh(),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            ))\n",
        "            in_features = units\n",
        "\n",
        "        # Output layers\n",
        "        self.adjacency_layer = nn.Sequential(\n",
        "            nn.Linear(dense_units[-1], BOND_DIM * NUM_ATOMS * NUM_ATOMS),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "        self.features_layer = nn.Sequential(\n",
        "            nn.Linear(dense_units[-1], NUM_ATOMS * ATOM_DIM),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = z\n",
        "        for dense in self.dense_layers:\n",
        "            x = dense(x)\n",
        "\n",
        "        # Reshape outputs\n",
        "        adjacency = self.adjacency_layer(x)\n",
        "        adjacency = adjacency.view(-1, BOND_DIM, NUM_ATOMS, NUM_ATOMS)\n",
        "        # Ensure symmetry\n",
        "        adjacency = (adjacency + adjacency.transpose(2, 3)) / 2\n",
        "\n",
        "        features = self.features_layer(x)\n",
        "        features = features.view(-1, NUM_ATOMS, ATOM_DIM)\n",
        "\n",
        "        return adjacency, features"
      ],
      "metadata": {
        "id": "8zct7e6v9mIX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MoleculeVAE(nn.Module):\n",
        "    def __init__(self, gconv_units=[9], dense_units=[512]):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(gconv_units, dense_units)\n",
        "        self.sampling = Sampling()\n",
        "        self.decoder = Decoder([128, 256, 512])\n",
        "        self.property_predictor = nn.Linear(LATENT_DIM, 1)\n",
        "\n",
        "    def forward(self, adjacency, features):\n",
        "        z_mean, z_log_var = self.encoder(adjacency, features)\n",
        "        z = self.sampling(z_mean, z_log_var)\n",
        "        gen_adjacency, gen_features = self.decoder(z)\n",
        "        property_pred = self.property_predictor(z_mean)\n",
        "\n",
        "        return z_mean, z_log_var, property_pred, gen_adjacency, gen_features\n",
        "\n",
        "    def compute_loss(self, z_mean, z_log_var, qed_true, qed_pred,\n",
        "                    adjacency_real, features_real,\n",
        "                    adjacency_gen, features_gen):\n",
        "        # Reconstruction loss\n",
        "        adjacency_loss = F.cross_entropy(\n",
        "            adjacency_gen.view(-1, BOND_DIM),\n",
        "            adjacency_real.view(-1, BOND_DIM)\n",
        "        )\n",
        "        features_loss = F.cross_entropy(\n",
        "            features_gen.view(-1, ATOM_DIM),\n",
        "            features_real.view(-1, ATOM_DIM)\n",
        "        )\n",
        "\n",
        "        # KL divergence\n",
        "        kl_loss = -0.5 * torch.sum(\n",
        "            1 + z_log_var - z_mean.pow(2) - z_log_var.exp(),\n",
        "            dim=1\n",
        "        ).mean()\n",
        "\n",
        "        # Property prediction loss\n",
        "        property_loss = F.binary_cross_entropy_with_logits(\n",
        "            qed_pred.squeeze(), qed_true\n",
        "        )\n",
        "\n",
        "        return adjacency_loss + features_loss + kl_loss + property_loss\n",
        "\n",
        "def train_model(model, train_loader, optimizer, device, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch_idx, (adjacency, features, qed) in enumerate(train_loader):\n",
        "            adjacency = adjacency.to(device)\n",
        "            features = features.to(device)\n",
        "            qed = qed.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            z_mean, z_log_var, qed_pred, gen_adjacency, gen_features = model(\n",
        "                adjacency, features\n",
        "            )\n",
        "\n",
        "            loss = model.compute_loss(\n",
        "                z_mean, z_log_var, qed, qed_pred,\n",
        "                adjacency, features,\n",
        "                gen_adjacency, gen_features\n",
        "            )\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}')"
      ],
      "metadata": {
        "id": "VeemWWH49rjJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # 데이터 로드\n",
        "    # 데이터 로드 및 전처리\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df[\"smiles\"] = df[\"smiles\"].apply(lambda s: s.replace(\"\\n\", \"\"))\n",
        "    print(\"\\n데이터 샘플:\")\n",
        "    print(df.head())\n",
        "    train_df = df.sample(frac=0.75, random_state=42)\n",
        "    train_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # 데이터셋 생성\n",
        "    dataset = MoleculeDataset(train_df)\n",
        "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # 디바이스 설정\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # 모델 초기화\n",
        "    model = MoleculeVAE().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
        "\n",
        "    # 학습\n",
        "    train_model(model, train_loader, optimizer, device, EPOCHS)\n",
        "\n",
        "    # 분자 생성\n",
        "    def generate_molecules(model, n_samples=1000):\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(n_samples, LATENT_DIM).to(device)\n",
        "            adjacency, features = model.decoder(z)\n",
        "\n",
        "            # Convert to numpy for RDKit processing\n",
        "            adjacency = adjacency.cpu().numpy()\n",
        "            features = features.cpu().numpy()\n",
        "\n",
        "            molecules = []\n",
        "            for i in range(n_samples):\n",
        "                mol = graph_to_molecule([adjacency[i], features[i]])\n",
        "                if mol is not None:\n",
        "                    molecules.append(mol)\n",
        "\n",
        "            return molecules\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3eaWfpK9wyq",
        "outputId": "c25a121c-d200-4800-ef7f-29bcac5560e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "데이터 샘플:\n",
            "                                              smiles     logP       qed  \\\n",
            "0            CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1  5.05060  0.702012   \n",
            "1       C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1  3.11370  0.928975   \n",
            "2  N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...  4.96778  0.599682   \n",
            "3  CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...  4.00022  0.690944   \n",
            "4  N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...  3.60956  0.789027   \n",
            "\n",
            "        SAS  \n",
            "0  2.084095  \n",
            "1  3.432004  \n",
            "2  2.470633  \n",
            "3  2.822753  \n",
            "4  4.035182  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d60857cc9b2d>:82: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  self.adjacency_tensor = torch.FloatTensor(self.adjacency_tensor)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Average Loss: 109.0409\n",
            "Epoch 2/10, Average Loss: 5.2328\n",
            "Epoch 3/10, Average Loss: 4.7633\n",
            "Epoch 4/10, Average Loss: 4.7126\n",
            "Epoch 5/10, Average Loss: 4.6857\n"
          ]
        }
      ]
    }
  ]
}